{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Prediction in Real Time Using Docker and Python REST APIs with Flask\n",
    "\n",
    "In this project, I want to show how to deploy a machine learning algorithm with a Python-Flask RESTful-API around a localhost Docker container and get real-time online predictions.\n",
    "\n",
    "To learn this concept, I will implement online inferences (Linear Discriminant Analysis and Multi-layer Perceptron Neural Network models) with Docker and Flask-RESTful.\n",
    "\n",
    "I found a pre-trained engine on EEG data that predicts the alphabet letter the human subject had thought.\n",
    "\n",
    "This guide wrote for Windows Terminal and if you have another OS you should change it if you need.\n",
    "\n",
    "In this guide I got some codes from @xaviervasques. \n",
    "\n",
    "## Install requirements\n",
    "\n",
    "Before we start, we should [install Docker](https://docs.docker.com/desktop/) on our computer. If you have Windows OS, it would be better to activate and install [Windows Subsystem for Linux (WSL) Version 2](https://docs.microsoft.com/en-us/windows/wsl/install) and then ubuntu distribution on it.\n",
    "\n",
    "After installation of Docker, we need to install [Python](https://hub.docker.com/_/python), [Scipy-notebook](https://hub.docker.com/r/jupyter/scipy-notebook) and [curl](https://hub.docker.com/r/curlimages/curl) on Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker pull python\n",
    "docker pull jupyter/scipy-notebook\n",
    "docker pull curlimages/curl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to clone [ML online prediction repository](https://github.com/magnooj/ml-online-prediction) from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/magnooj/ml-online-prediction.git\n",
    "cd ml-online-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Through the files\n",
    "\n",
    "Now, we are ready to run and test our project. By running `ls` you can see these files:\n",
    "\n",
    "- [`api.py`](https://github.com/magnooj/ml-online-prediction/blob/main/api.py) : Python-Flask RESTful-API\n",
    "- [`Dockerfile`](https://github.com/magnooj/ml-online-prediction/blob/main/Dockerfile) : Docker container\n",
    "- [`README.md`](https://github.com/magnooj/ml-online-prediction/blob/main/README.md) : Instructions\n",
    "- [`requirements.txt`](https://github.com/magnooj/ml-online-prediction/blob/main/requirements.txt) : Required modules to run this project\n",
    "- [`test.json`](https://github.com/magnooj/ml-online-prediction/blob/main/test.json) : Dataset for test the app\n",
    "- [`train.csv`](https://github.com/magnooj/ml-online-prediction/blob/main/train.csv) : Dataset for train the app\n",
    "- [`train.py`](https://github.com/magnooj/ml-online-prediction/blob/main/train.py) : Machine Learning app\n",
    "\n",
    "The ``train.py`` is a python script that ingest and normalize EEG data and train two models to classify the data. The `Dockerfile` will be used to build our Docker image, `requirements.txt` *(flask, flask-restful, joblib)* is for the Python dependencies and `api.py` is the script that will be called to perform the online inference using *REST APIs*. `train.csv` are the data used to train our models, and `test.json` is a file containing new EEG data that will be used with our inference models.\n",
    "\n",
    "### ***Flask RESTful APIs***\n",
    "\n",
    "The first step in building *APIs* is to think about the data we want to handle, how we want to handle it and what output we want with our *APIs*. In our example, we will use the `test.json` file in which we have 1300 rows of EEG data with 160 features each (columns). We want our *APIs* to the following:\n",
    "\n",
    "- ***API 1***: We will give a row number to the API which will extract for us the data from the selected row and print it.\n",
    "- ***API 2***: We will give a row number to the API which will extract the selected row, inject the new data into the models and retrieve the classification prediction (Letter variable in the data).\n",
    "- ***API 3***: We will ask the API to take all the data in the test.json file and instantly print us the classification score of the models.\n",
    "\n",
    "At the end, we want to access those processes by making an HTTP request.\n",
    "Letâ€™s have a look at the `api.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from flask import Flask\n",
    "\n",
    "# Set environment variables\n",
    "MODEL_DIR = os.environ[\"MODEL_DIR\"]\n",
    "MODEL_FILE_LDA = os.environ[\"MODEL_FILE_LDA\"]\n",
    "MODEL_FILE_NN = os.environ[\"MODEL_FILE_NN\"]\n",
    "MODEL_PATH_LDA = os.path.join(MODEL_DIR, MODEL_FILE_LDA)\n",
    "MODEL_PATH_NN = os.path.join(MODEL_DIR, MODEL_FILE_NN)\n",
    "\n",
    "# Loading LDA model\n",
    "print(\"Loading model from: {}\".format(MODEL_PATH_LDA))\n",
    "inference_lda = load(MODEL_PATH_LDA)\n",
    "\n",
    "# loading Neural Network model\n",
    "print(\"Loading model from: {}\".format(MODEL_PATH_NN))\n",
    "inference_NN = load(MODEL_PATH_NN)\n",
    "\n",
    "# Creation of the Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# API 1\n",
    "# Flask route so that we can serve HTTP traffic on that route\n",
    "@app.route('/line/<Line>')\n",
    "# Get data from json and return the requested row defined by the variable Line\n",
    "def line(Line):\n",
    "    with open('./test.json', 'r') as jsonfile:\n",
    "       file_data = json.loads(jsonfile.read())\n",
    "    # We can then find the data for the requested row and send it back as json\n",
    "    return json.dumps(file_data[Line])\n",
    "    \n",
    "\n",
    "# API 2\n",
    "# Flask route so that we can serve HTTP traffic on that route\n",
    "@app.route('/prediction/<int:Line>',methods=['POST', 'GET'])\n",
    "# Return prediction for both Neural Network and LDA inference model with the requested row as input\n",
    "def prediction(Line):\n",
    "    data = pd.read_json('./test.json')\n",
    "    data_test = data.transpose()\n",
    "    X = data_test.drop(data_test.loc[:, 'Line':'# Letter'].columns, axis = 1)\n",
    "    X_test = X.iloc[Line,:].values.reshape(1, -1)\n",
    "    \n",
    "    clf_lda = load(MODEL_PATH_LDA)\n",
    "    prediction_lda = clf_lda.predict(X_test)\n",
    "    \n",
    "    clf_nn = load(MODEL_PATH_NN)\n",
    "    prediction_nn = clf_nn.predict(X_test)\n",
    "    \n",
    "    return {'prediction LDA': int(prediction_lda), 'prediction Neural Network': int(prediction_nn)}\n",
    "\n",
    "# API 3\n",
    "# Flask route so that we can serve HTTP traffic on that route\n",
    "@app.route('/score',methods=['POST', 'GET'])\n",
    "# Return classification score for both Neural Network and LDA inference model from the all dataset provided\n",
    "def score():\n",
    "\n",
    "    data = pd.read_json('./test.json')\n",
    "    data_test = data.transpose()\n",
    "    y_test = data_test['# Letter'].values\n",
    "    X_test = data_test.drop(data_test.loc[:, 'Line':'# Letter'].columns, axis = 1)\n",
    "    \n",
    "    clf_lda = load(MODEL_PATH_LDA)\n",
    "    score_lda = clf_lda.score(X_test, y_test)\n",
    "    \n",
    "    clf_nn = load(MODEL_PATH_NN)\n",
    "    score_nn = clf_nn.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score LDA': score_lda, 'Score Neural Network': score_nn}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host='0.0.0.0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step, after importing dependencies including the open source web micro-framework Flask, is to set the environment variables that are written in the Dockerfile. We also need to load our *Linear Discriminant Analysis (LDA)* and *Multi-layer Perceptron Neural Network (NN)* serialized models. We create our Flask application by writing `app = Flask(__name__)`. Then, we create our three Flask routes so that we can serve HTTP traffic on that route:\n",
    "\n",
    "- http://localhost:5000/line/250 : Get data from `test.json` and return the requested row defined by the variable Line (in this example we want to extract the data of row number 250).\n",
    "- http://localhost:5000/prediction/51 : Returns classification prediction from both LDA and Neural Network trained models by injecting the requested data (in this example, we want to inject the data of row number 51).\n",
    "- http://localhost:5000/score : Return classification score for both the *Neural Network* and *LDA* inference models on all the available data (`test.json`).\n",
    "\n",
    "The Flask routes allows us to request what we need from the API by adding the name of our procedure (`/line/<Line>`, `/prediction/<int:Line>`, `/score`) to the URL (http://localhost:5000). Whatever the data we add, `api.py` will always return the output we request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning models\n",
    "The `train.py` is a python script that ingests and normalizes EEG data in a csv file (`train.csv`) and train two models to classify the data (using `scikit-learn`). The script saves two models: Linear Discriminant Analysis (`clf_lda`) and Neural Networks multi-layer perceptron (`clf_NN`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# tain.py\n",
    "# Debug and edit: Ali Ganjizadeh(@magnooj) 22/01/2022; Original code: @xaviervasques\n",
    "\n",
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train():\n",
    "\n",
    "    # Load directory paths for persisting model\n",
    "    MODEL_DIR = os.environ[\"MODEL_DIR\"]\n",
    "    MODEL_FILE_LDA = os.environ[\"MODEL_FILE_LDA\"]\n",
    "    MODEL_FILE_NN = os.environ[\"MODEL_FILE_NN\"]\n",
    "    MODEL_PATH_LDA = os.path.join(MODEL_DIR, MODEL_FILE_LDA)\n",
    "    MODEL_PATH_NN = os.path.join(MODEL_DIR, MODEL_FILE_NN)\n",
    "      \n",
    "    # Load, read and normalize training data\n",
    "    training = \"./train.csv\"\n",
    "    data_train = pd.read_csv(training)\n",
    "        \n",
    "    y_train = data_train['# Letter'].values\n",
    "    X_train = data_train.drop(data_train.loc[:, 'Line':'# Letter'].columns, axis = 1)\n",
    "\n",
    "    print(\"Shape of the training data\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "        \n",
    "    # Data normalization (0,1)\n",
    "    X_train = preprocessing.normalize(X_train, norm='l2')\n",
    "    \n",
    "    # Models training\n",
    "    \n",
    "    # Linear Discrimant Analysis (Default parameters)\n",
    "    clf_lda = LinearDiscriminantAnalysis()\n",
    "    clf_lda.fit(X_train, y_train)\n",
    "    \n",
    "    # Serialize model\n",
    "    from joblib import dump\n",
    "    dump(clf_lda, MODEL_PATH_LDA)\n",
    "        \n",
    "    # Neural Networks multi-layer perceptron (MLP) algorithm\n",
    "    clf_NN = MLPClassifier(solver='adam', activation='relu', alpha=0.0001, hidden_layer_sizes=(500,), random_state=0, max_iter=1000)\n",
    "    clf_NN.fit(X_train, y_train)\n",
    "       \n",
    "    # Serialize model\n",
    "    from joblib import dump, load\n",
    "    dump(clf_NN, MODEL_PATH_NN)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run APIs through a Docker container\n",
    "\n",
    "We have all to build our [Docker Image](https://docs.docker.com/engine/reference/commandline/images/). To start, we need our `Dockerfile` with the `jupyter/scipy-notebook` image as our base image. We also need to set our environment variables and install `joblib` to allow serialization and deserialization of our trained models and flask (`requirements.txt`).\n",
    "\n",
    "### ***Create a Docker Image***\n",
    "\n",
    "After installation of Docker App, we should create a [Docker Image](https://docs.docker.com/engine/reference/commandline/images/). Thus, we copy the `train.csv`, `test.json`, `train.py` and `api.py` files into the image. Then, we run `train.py` which will fit and serialize the machine learning models as part of our image build process.\n",
    "\n",
    "Here is the Dockerfile code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM jupyter/scipy-notebook\n",
    "\n",
    "RUN mkdir my-model\n",
    "ENV MODEL_DIR=/home/jovyan/my-model\n",
    "ENV MODEL_FILE_LDA=clf_lda.joblib\n",
    "ENV MODEL_FILE_NN=clf_nn.joblib\n",
    "\n",
    "COPY requirements.txt ./requirements.txt\n",
    "RUN pip install -r requirements.txt \n",
    "\n",
    "COPY train.csv ./train.csv\n",
    "COPY test.json ./test.json\n",
    "\n",
    "COPY train.py ./train.py\n",
    "COPY api.py ./api.py\n",
    "\n",
    "\n",
    "RUN python train.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build this image, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker build -t my-docker-api -f Dockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get this output:\n",
    "\n",
    "<img src=\"https://github.com/magnooj/ml-online-prediction/blob/main/images/1.png?raw=true\" alt=\"Picture of copying files in container\">\n",
    "\n",
    "We can see our images by `Docker images` command: :\n",
    "\n",
    "<img src=\"https://github.com/magnooj/ml-online-prediction/blob/main/images/2.png?raw=true\" alt=\"Picture of Docker repositories\">\n",
    "\n",
    "### ***Serve a Docker container***\n",
    "\n",
    "Now the goal is to run our online inference meaning that each time a client issues a POST request to the `/line/<Line>`, `/prediction/<Line>`, `/score endpoints`, we will show the requested data (row), predict the class of the data we inject using our pre-trained models, and the score of our pre-trained models using all the available data. To launch the web server, we will run a Docker container and run the `api.py` script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run -it -p 5000:5000 my-docker-api python api.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-p` flag exposes port `5000` in the container to `port 5000` on our host machine, `-it` flag allows us to see the logs from the container and we run `python api.py` in the `my-api` image.\n",
    "\n",
    "The output is the following:\n",
    "\n",
    "<img src=\"https://github.com/magnooj/ml-online-prediction/blob/main/images/3.png?raw=true\" alt=\"Picture of Docker server start\">\n",
    "\n",
    "You can see that we are running on http://localhost:5000/ and we can now use our web browser or the `curl` command to issue a POST request to the IP address.\n",
    "\n",
    "If we type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:5000/line/232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get row number 232 extracted from our data (`test.json`):\n",
    "\n",
    "<img src=\"https://github.com/magnooj/ml-online-prediction/blob/main/images/4.png?raw=true\" alt=\"Picture curl jason data\">\n",
    "\n",
    "Same result using the web browser:\n",
    "\n",
    "<img src=\"https://github.com/magnooj/ml-online-prediction/blob/main/images/5.png?raw=true\" alt=\"Picture of browser data\">\n",
    "\n",
    "If we type the following `curl` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://localhost:5000/prediction/232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see the following output:\n",
    "\n",
    "<img src=\"https://github.com/magnooj/ml-online-prediction/blob/main/images/6.png?raw=true\" alt=\"Picture of predicting the given EEG\">\n",
    "\n",
    "The above output means that the LDA model classified the provided data (*row 232*) as letter 21 (*U*) while Multi-layer Perceptron Neural Network classified the data as letter 8 (*H*). The two models do not agree.\n",
    "\n",
    "If we type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl http://lohalhost:5000/score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see the score of our models on the entire dataset:\n",
    "\n",
    "<img src=\"https://github.com/magnooj/ml-online-prediction/blob/main/images/7.png?raw=true\" alt=\"Picture of accuracy of two models\">\n",
    "\n",
    "As we can read, we should trust more the Multi-layer Perceptron Neural Network with an accuracy score of `0.59` even if the score is not so high.\n",
    "\n",
    "I hope you enjoyed how to containerizing your machine/deep learning applications using Docker and flask to perform online inference. if you have any comments please do not hesitate to send me an [e-mail](mailto:magnooj@gmail.com).\n",
    "\n",
    "Regards,\n",
    "\n",
    "Ali Ganjizadeh\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
